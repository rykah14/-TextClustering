{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_hcos_5000_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1tB2GtAbuSk8gTc2jXOs2XYRoC2SGRoS0",
      "authorship_tag": "ABX9TyOTJKxYv1pmWc+8oCVsQdqH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fbc0b671f195481ebb7e688929b81c2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_92bcf2ea1b0d46cdaee03218747eaac6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7a4dd423dff448d09733c6ca997879ce",
              "IPY_MODEL_4513481102ae49cabec1dee45660e65d",
              "IPY_MODEL_a9bffbafea214d9c8692cb65bc157d23"
            ]
          }
        },
        "92bcf2ea1b0d46cdaee03218747eaac6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7a4dd423dff448d09733c6ca997879ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_eabe161611dc4c88be12f9e34a1fe5a9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_425fdd8302dd4a8dad426b5749ec40bd"
          }
        },
        "4513481102ae49cabec1dee45660e65d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7e765309dfd54661805b20e9b005d418",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cefb374c755a4e878a853e1f37e80103"
          }
        },
        "a9bffbafea214d9c8692cb65bc157d23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d0e43165a5aa4585ad0f685658bfae04",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 226k/226k [00:00&lt;00:00, 911kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eefde411775e4a66b81bcd1fae4cf5c8"
          }
        },
        "eabe161611dc4c88be12f9e34a1fe5a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "425fdd8302dd4a8dad426b5749ec40bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7e765309dfd54661805b20e9b005d418": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cefb374c755a4e878a853e1f37e80103": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d0e43165a5aa4585ad0f685658bfae04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eefde411775e4a66b81bcd1fae4cf5c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ae94fce9778d4aaabe107adf3d8ccaff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4948d460f9204f0aa9e22b444dde1d8a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3971e90f7422434b826dfa095b09d574",
              "IPY_MODEL_122e5635ebb746a0bb583eb30565d13e",
              "IPY_MODEL_5f6c74aa45604f09b073161bedfd13e4"
            ]
          }
        },
        "4948d460f9204f0aa9e22b444dde1d8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3971e90f7422434b826dfa095b09d574": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bb0445064b5b47ae8ed0b647f6658a51",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6125f21af49a463db3e20e7b2d0f2ebe"
          }
        },
        "122e5635ebb746a0bb583eb30565d13e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9bcebaadf8c54d1ca446335cc44f0f20",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_019af90ae2be41b8b344510984fba510"
          }
        },
        "5f6c74aa45604f09b073161bedfd13e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_75d4804b508b4d7580af76c171f9463f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 634B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d289d8d678d84395a0cd34eb62ffde03"
          }
        },
        "bb0445064b5b47ae8ed0b647f6658a51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6125f21af49a463db3e20e7b2d0f2ebe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9bcebaadf8c54d1ca446335cc44f0f20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "019af90ae2be41b8b344510984fba510": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "75d4804b508b4d7580af76c171f9463f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d289d8d678d84395a0cd34eb62ffde03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ad264d0c4f12404a8e5954af57744ca0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b2c9bad300154061bd6f1e442ad7fe77",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6b082946d7214600a5f6ec0b2744154d",
              "IPY_MODEL_27de26760ed94bfea73f638cba0ab176",
              "IPY_MODEL_1a71700b47484e3b929d759116bb133d"
            ]
          }
        },
        "b2c9bad300154061bd6f1e442ad7fe77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6b082946d7214600a5f6ec0b2744154d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0f6ff30048ca45899c0e4f79633882ac",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_20f947253f7e4735a38a2c913fccd9f9"
          }
        },
        "27de26760ed94bfea73f638cba0ab176": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_282f6a28f5274babb1efe2f3378ccbbe",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5b3b4cddb12245dba3bee2c99ee8b288"
          }
        },
        "1a71700b47484e3b929d759116bb133d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b6fb39d64e114deca8cd552ad3627505",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 455k/455k [00:00&lt;00:00, 1.11MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3a8751d22cc24829865cd5f2f70bb538"
          }
        },
        "0f6ff30048ca45899c0e4f79633882ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "20f947253f7e4735a38a2c913fccd9f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "282f6a28f5274babb1efe2f3378ccbbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5b3b4cddb12245dba3bee2c99ee8b288": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b6fb39d64e114deca8cd552ad3627505": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3a8751d22cc24829865cd5f2f70bb538": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "20712b5a4aeb45a482762d2ba2667ce5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8ea7ab30751e45cc8b64561ef8d15901",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2a606961032f4c4780fe83aa14e4e358",
              "IPY_MODEL_266e76989ab347359928500f1a7fcff7",
              "IPY_MODEL_7f230d1903704dcbaee27851beec9fee"
            ]
          }
        },
        "8ea7ab30751e45cc8b64561ef8d15901": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2a606961032f4c4780fe83aa14e4e358": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b68df929e2104dbea373c62a071485e4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_df391edcd2af4b95adf3eb306520ca12"
          }
        },
        "266e76989ab347359928500f1a7fcff7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f9bf2103c0644903883baa9a6e96d771",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_111d695a729e49c3b6ef3796e9b197ed"
          }
        },
        "7f230d1903704dcbaee27851beec9fee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_20427dcd88f74c2d8c00870307abfc8c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 16.7kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fec2db7ecafa42b7b805b8404326f097"
          }
        },
        "b68df929e2104dbea373c62a071485e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "df391edcd2af4b95adf3eb306520ca12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f9bf2103c0644903883baa9a6e96d771": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "111d695a729e49c3b6ef3796e9b197ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "20427dcd88f74c2d8c00870307abfc8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fec2db7ecafa42b7b805b8404326f097": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "33e6f6fbd00f4ce9a1b7c4183e8c5c57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0390a53b662e41ac9dfb156f0373ce92",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fcdc854282fb4e86916d33b771cb796e",
              "IPY_MODEL_e8ead906a1724e39b52e8eeac88b538f",
              "IPY_MODEL_4000c65f853644a593a5afdefab0d8e9"
            ]
          }
        },
        "0390a53b662e41ac9dfb156f0373ce92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fcdc854282fb4e86916d33b771cb796e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bd83fd28aaaf4a36af3e966d759b0112",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_613412fe4299459cb79e9bd87641ce48"
          }
        },
        "e8ead906a1724e39b52e8eeac88b538f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ac317f81380d439b83a47980d27d8af7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5dcb1337d3074bb6ab9862af0390ddac"
          }
        },
        "4000c65f853644a593a5afdefab0d8e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_92e04bb4755749b7a84539cc2194e9a5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 420M/420M [00:08&lt;00:00, 48.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_054ea5b890594808bb829f45c5ae98c1"
          }
        },
        "bd83fd28aaaf4a36af3e966d759b0112": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "613412fe4299459cb79e9bd87641ce48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ac317f81380d439b83a47980d27d8af7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5dcb1337d3074bb6ab9862af0390ddac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "92e04bb4755749b7a84539cc2194e9a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "054ea5b890594808bb829f45c5ae98c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rykah14/-TextClustering/blob/main/test_for_method.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLJShceY_jYM"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPjC5oBSmko1",
        "outputId": "f876655e-e035-4e37-c1ac-140e52229058"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmFO1My4mv9Q",
        "outputId": "a3e68758-141f-4412-cbb1-71bc972c0eed"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 5.1 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.1.2-py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 7.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 52.8 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 60.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 79.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.1.2 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "7OvGefqm0d5c",
        "outputId": "91749210-f9ce-4df4-e4f7-a9569a60d505"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/My Drive/reddit.csv\")\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sentences: 1,000,000\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subreddit</th>\n",
              "      <th>body</th>\n",
              "      <th>controversiality</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>470773</th>\n",
              "      <td>todayilearned</td>\n",
              "      <td>That scene was cut out of the UK release becau...</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>160561</th>\n",
              "      <td>movies</td>\n",
              "      <td>I don't see how it was a joke but ok.</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516772</th>\n",
              "      <td>marvelstudios</td>\n",
              "      <td>The in universe explanation for this was that ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>537996</th>\n",
              "      <td>nfl</td>\n",
              "      <td>Oh good I'm sick again.\\n\\n\\nFuck 3rd and 4th ...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>723974</th>\n",
              "      <td>leagueoflegends</td>\n",
              "      <td>I got dia on my smurf with 75%winrate and i go...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>661143</th>\n",
              "      <td>teenagers</td>\n",
              "      <td>No it’s not from twitch rofl</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42374</th>\n",
              "      <td>nba</td>\n",
              "      <td>Well, you can't celebrate in a FT line. Doesn'...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74449</th>\n",
              "      <td>nba</td>\n",
              "      <td>It surprised me as well even before I saw your...</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80947</th>\n",
              "      <td>AskReddit</td>\n",
              "      <td>Honestly I love my hospice patients so much. W...</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>382400</th>\n",
              "      <td>pics</td>\n",
              "      <td>I'm just suggesting you keep your bullshit to ...</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              subreddit  ... score\n",
              "470773    todayilearned  ...    11\n",
              "160561           movies  ...     0\n",
              "516772    marvelstudios  ...     1\n",
              "537996              nfl  ...     2\n",
              "723974  leagueoflegends  ...     0\n",
              "661143        teenagers  ...     2\n",
              "42374               nba  ...     1\n",
              "74449               nba  ...     7\n",
              "80947         AskReddit  ...    12\n",
              "382400             pics  ...     4\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hvs-e334xQt",
        "outputId": "c1b169c0-af1c-4627-84d2-e977736d52bd"
      },
      "source": [
        "print(\"subreddit多いもの順50\")\n",
        "count_df = df[['subreddit','body']].groupby('subreddit').aggregate({'body':'count'}).reset_index().sort_values('subreddit',ascending=True)\n",
        "print(count_df.head(50))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "subreddit多いもの順50\n",
            "              subreddit   body\n",
            "0         AmItheAsshole  25000\n",
            "1              Animemes  25000\n",
            "2             AskReddit  25000\n",
            "3        ChapoTrapHouse  25000\n",
            "4            FortNiteBR  25000\n",
            "5              Market76  25000\n",
            "6          MortalKombat  25000\n",
            "7                Pikabu  25000\n",
            "8               RoastMe  25000\n",
            "9        Showerthoughts  25000\n",
            "10        SquaredCircle  25000\n",
            "11           The_Donald  25000\n",
            "12          apexlegends  25000\n",
            "13               asoiaf  25000\n",
            "14                  aww  25000\n",
            "15            dankmemes  25000\n",
            "16             freefolk  25000\n",
            "17                funny  25000\n",
            "18        gameofthrones  25000\n",
            "19               gaming  25000\n",
            "20             gonewild  25000\n",
            "21               hockey  25000\n",
            "22      leagueoflegends  25000\n",
            "23        marvelstudios  25000\n",
            "24                memes  25000\n",
            "25               movies  25000\n",
            "26                  nba  25000\n",
            "27                 news  25000\n",
            "28                  nfl  25000\n",
            "29                 pics  25000\n",
            "30             politics  25000\n",
            "31  relationship_advice  25000\n",
            "32               soccer  25000\n",
            "33            teenagers  25000\n",
            "34        todayilearned  25000\n",
            "35               trashy  25000\n",
            "36     unpopularopinion  25000\n",
            "37               videos  25000\n",
            "38       wallstreetbets  25000\n",
            "39            worldnews  25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4B_Ttt6VDaO",
        "outputId": "3d1ab75d-0a6c-4865-9cf4-897fb0a9db26"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# データの読込\n",
        "\n",
        "# データの抽出\n",
        "df_0 = df.loc[df['subreddit'].isin(['news']), ['subreddit', 'body']]\n",
        "df_0=df_0.replace('news',0)\n",
        "split_dataset_0,discard_0=train_test_split(df_0, train_size=(5000/25000)) \n",
        "print(\"使えるデータセット\")\n",
        "print(split_dataset_0)\n",
        "\n",
        "df_1 = df.loc[df['subreddit'].isin(['worldnews']), ['subreddit', 'body']]\n",
        "df_1=df_1.replace('worldnews',1)\n",
        "split_dataset_1 ,discard_1= train_test_split(df_1, train_size=(5000/25000))\n",
        "print(\"使えるデータセット\")\n",
        "print(split_dataset_1)\n",
        "\n",
        "\n",
        "\n",
        "list=[]\n",
        "list.append(split_dataset_0)\n",
        "list.append(split_dataset_1)\n",
        "\n",
        "\n",
        "\n",
        "df = pd.concat(list, sort=False)\n",
        "print(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "使えるデータセット\n",
            "        subreddit                                               body\n",
            "769380          0  Right, she got expelled, but the people that l...\n",
            "672824          0  Hey if it brings attention to their ecological...\n",
            "29380           0  Need more guns and walls to keep out foreigner...\n",
            "158488          0  I’m a student of UNCC and luckily wasn’t on ca...\n",
            "393740          0  Did you read the article...It means a women’s ...\n",
            "...           ...                                                ...\n",
            "655485          0               You could just... not eat meat 🤷🏻‍♀️\n",
            "638236          0   Why don't they do this to wasps?! We need bees 💔\n",
            "541130          0  Sorry, I didn't mean to suggest everyone who o...\n",
            "189916          0  This is stupid advice. If there are rumors of ...\n",
            "201154          0  You're right, that's from dying in a mass shoo...\n",
            "\n",
            "[5000 rows x 2 columns]\n",
            "使えるデータセット\n",
            "        subreddit                                               body\n",
            "34769           1                    Didn't Maduro win the election?\n",
            "24356           1  The coup suspects were known members of the Gu...\n",
            "560786          1  Again, I'm not talking about formula. But yes,...\n",
            "367815          1  The Swedes may get first go at him for the \"ra...\n",
            "19703           1  &gt; https://www.cnn.com/2018/01/26/us/hate-cr...\n",
            "...           ...                                                ...\n",
            "394380          1  I'm not a T_D poster, the fact you guys are le...\n",
            "126315          1  &gt; that hasn't defended you or benefited you...\n",
            "90076           1  You don't seem to understand that I'm an anarc...\n",
            "96008           1                                    lol what a trip\n",
            "111712          1  So now you are implying that there aren't a lo...\n",
            "\n",
            "[5000 rows x 2 columns]\n",
            "        subreddit                                               body\n",
            "769380          0  Right, she got expelled, but the people that l...\n",
            "672824          0  Hey if it brings attention to their ecological...\n",
            "29380           0  Need more guns and walls to keep out foreigner...\n",
            "158488          0  I’m a student of UNCC and luckily wasn’t on ca...\n",
            "393740          0  Did you read the article...It means a women’s ...\n",
            "...           ...                                                ...\n",
            "394380          1  I'm not a T_D poster, the fact you guys are le...\n",
            "126315          1  &gt; that hasn't defended you or benefited you...\n",
            "90076           1  You don't seem to understand that I'm an anarc...\n",
            "96008           1                                    lol what a trip\n",
            "111712          1  So now you are implying that there aren't a lo...\n",
            "\n",
            "[10000 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Et6IqXeskSkn",
        "outputId": "62102665-2e75-4871-b3b4-3d3ada3ffe48"
      },
      "source": [
        "print(df.sample(10))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        subreddit                                               body\n",
            "255049          1  Living on different continents and seeing each...\n",
            "395878          1  That's the central question involving our envi...\n",
            "601718          1  The precedent is for the Presidential candidat...\n",
            "767519          0   Read this as \"fish-shaking\", made it even better\n",
            "175742          0  \"If you can't deal with bullshit that only eve...\n",
            "771393          0  &gt; Her family got scammed. \\n\\nAnd they prob...\n",
            "642814          1  You son of a bitch. Do you know how much disap...\n",
            "20350           0  That’s fucking terrifying. What would make som...\n",
            "512578          1  &gt; At least under Trump we don't have to dea...\n",
            "456788          1  That's great. Now provide evidence that this i...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "hqjLnuCQnbfL",
        "outputId": "f343bf1d-27ec-4a3e-d42b-af8b9e50f881"
      },
      "source": [
        "df.loc[df.subreddit == 0].sample(5)[['subreddit','body']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subreddit</th>\n",
              "      <th>body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>135740</th>\n",
              "      <td>0</td>\n",
              "      <td>I believe it's march for our lives? Pretty sur...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>444840</th>\n",
              "      <td>0</td>\n",
              "      <td>I don't think we disagree. My overall point is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36565</th>\n",
              "      <td>0</td>\n",
              "      <td>Giving out red pills for breakfast</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188005</th>\n",
              "      <td>0</td>\n",
              "      <td>Citation needed on the swimming pool deaths. I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129637</th>\n",
              "      <td>0</td>\n",
              "      <td>Judging by your post history I think you might...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        subreddit                                               body\n",
              "135740          0  I believe it's march for our lives? Pretty sur...\n",
              "444840          0  I don't think we disagree. My overall point is...\n",
              "36565           0                 Giving out red pills for breakfast\n",
              "188005          0  Citation needed on the swimming pool deaths. I...\n",
              "129637          0  Judging by your post history I think you might..."
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4PBek_tnvi8"
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "subreddits = df.subreddit.values\n",
        "bodys = df.body.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeM-JgfvrcU6",
        "outputId": "6373e27a-050b-4db0-bc52-5c4e601d3a30"
      },
      "source": [
        "print(bodys[1:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hey if it brings attention to their ecological importance and the dire consequences off a mass die-off then I’m ok with it.\\n\\nWon’t watch it, but I’m ok with it.\\n\\nPlus “Bee Wars” just sounds badass.'\n",
            " 'Need more guns and walls to keep out foreigners, obviously. /s'\n",
            " 'I’m a student of UNCC and luckily wasn’t on campus. I have tons of friends who were though. They are just NOW allowing students to leave. This was the last day of class. I had just presented my senior design project. I had a friend who was barricaded in a room in the building adjacent to the one it occurred in. I have class in that building every week.  I’m at a loss for words.'\n",
            " 'Did you read the article...It means a women’s with an abnormally high level of testosterone will have more muscle mass, be physically stronger, and have better endurance. The ruling seeks to ensure all female participants are competing equally without the biological inherent advantage of elevated testosterone'\n",
            " 'Is Sea horse with no name next?'\n",
            " 'Maybe I’m the odd one - but when someone “jokes” about rape - I take them seriously. \\n\\nI don’t laugh. I don’t go “oh you’re only *joking* about raping teenage girls and dragging women to rape them. Oh good show good sir!”\\n\\nNah. If they’re going to “make jokes”, then I’ll assume they’re rapists. \\n\\nYou are who you pretend to be. \\n\\nSo be careful what you pretend to be.'\n",
            " 'Waaaiiit.  Unless bags of coke are being dumped in the water, is this implying that cocaine is being tansported through human waste?   Meaning cocaine can be harvested from human waste?  Meaning the waste water plant near me that can process a million gallons of wastewater a day somewhere has a bunch of disgusting goop that has coke in it?   I just thought of a plot for a movie.'\n",
            " 'a)\\n\\nThe militia of the\\xa0United States\\xa0consists of all able-bodied males at least 17 years of age and, except as provided in\\xa0section 313 of title 32, under 45 years of age who are, or who have made a declaration of intention to become, citizens of the\\xa0United States\\xa0and of female citizens of the\\xa0United States\\xa0who are members of the\\xa0National Guard.\\n\\nMilitia is every male age 17-45.'\n",
            " 'Which are far less lethal and therefore infinitely preferable. Lots of stabbings in the uk. Their homicide rate is a tiny fraction of ours']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162,
          "referenced_widgets": [
            "fbc0b671f195481ebb7e688929b81c2d",
            "92bcf2ea1b0d46cdaee03218747eaac6",
            "7a4dd423dff448d09733c6ca997879ce",
            "4513481102ae49cabec1dee45660e65d",
            "a9bffbafea214d9c8692cb65bc157d23",
            "eabe161611dc4c88be12f9e34a1fe5a9",
            "425fdd8302dd4a8dad426b5749ec40bd",
            "7e765309dfd54661805b20e9b005d418",
            "cefb374c755a4e878a853e1f37e80103",
            "d0e43165a5aa4585ad0f685658bfae04",
            "eefde411775e4a66b81bcd1fae4cf5c8",
            "ae94fce9778d4aaabe107adf3d8ccaff",
            "4948d460f9204f0aa9e22b444dde1d8a",
            "3971e90f7422434b826dfa095b09d574",
            "122e5635ebb746a0bb583eb30565d13e",
            "5f6c74aa45604f09b073161bedfd13e4",
            "bb0445064b5b47ae8ed0b647f6658a51",
            "6125f21af49a463db3e20e7b2d0f2ebe",
            "9bcebaadf8c54d1ca446335cc44f0f20",
            "019af90ae2be41b8b344510984fba510",
            "75d4804b508b4d7580af76c171f9463f",
            "d289d8d678d84395a0cd34eb62ffde03",
            "ad264d0c4f12404a8e5954af57744ca0",
            "b2c9bad300154061bd6f1e442ad7fe77",
            "6b082946d7214600a5f6ec0b2744154d",
            "27de26760ed94bfea73f638cba0ab176",
            "1a71700b47484e3b929d759116bb133d",
            "0f6ff30048ca45899c0e4f79633882ac",
            "20f947253f7e4735a38a2c913fccd9f9",
            "282f6a28f5274babb1efe2f3378ccbbe",
            "5b3b4cddb12245dba3bee2c99ee8b288",
            "b6fb39d64e114deca8cd552ad3627505",
            "3a8751d22cc24829865cd5f2f70bb538",
            "20712b5a4aeb45a482762d2ba2667ce5",
            "8ea7ab30751e45cc8b64561ef8d15901",
            "2a606961032f4c4780fe83aa14e4e358",
            "266e76989ab347359928500f1a7fcff7",
            "7f230d1903704dcbaee27851beec9fee",
            "b68df929e2104dbea373c62a071485e4",
            "df391edcd2af4b95adf3eb306520ca12",
            "f9bf2103c0644903883baa9a6e96d771",
            "111d695a729e49c3b6ef3796e9b197ed",
            "20427dcd88f74c2d8c00870307abfc8c",
            "fec2db7ecafa42b7b805b8404326f097"
          ]
        },
        "id": "6Ynw9e--oOAk",
        "outputId": "af74f8d9-6121-4d61-81e1-91cb3bb57f22"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fbc0b671f195481ebb7e688929b81c2d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae94fce9778d4aaabe107adf3d8ccaff",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ad264d0c4f12404a8e5954af57744ca0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "20712b5a4aeb45a482762d2ba2667ce5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVWEoGPfoPpF",
        "outputId": "90490f49-3671-4bf5-f9bb-7f11b56829cb"
      },
      "source": [
        "tokenizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PreTrainedTokenizer(name_or_path='bert-base-uncased', vocab_size=30522, model_max_len=512, is_fast=False, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfKYmw-zoUK6",
        "outputId": "156d272c-e121-4d50-f611-5face233edca"
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', bodys[1])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(bodys[1]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(bodys[1])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Original:  Hey if it brings attention to their ecological importance and the dire consequences off a mass die-off then I’m ok with it.\n",
            "\n",
            "Won’t watch it, but I’m ok with it.\n",
            "\n",
            "Plus “Bee Wars” just sounds badass.\n",
            "Tokenized:  ['hey', 'if', 'it', 'brings', 'attention', 'to', 'their', 'ecological', 'importance', 'and', 'the', 'dire', 'consequences', 'off', 'a', 'mass', 'die', '-', 'off', 'then', 'i', '’', 'm', 'ok', 'with', 'it', '.', 'won', '’', 't', 'watch', 'it', ',', 'but', 'i', '’', 'm', 'ok', 'with', 'it', '.', 'plus', '“', 'bee', 'wars', '”', 'just', 'sounds', 'bad', '##ass', '.']\n",
            "Token IDs:  [4931, 2065, 2009, 7545, 3086, 2000, 2037, 12231, 5197, 1998, 1996, 18704, 8465, 2125, 1037, 3742, 3280, 1011, 2125, 2059, 1045, 1521, 1049, 7929, 2007, 2009, 1012, 2180, 1521, 1056, 3422, 2009, 1010, 2021, 1045, 1521, 1049, 7929, 2007, 2009, 1012, 4606, 1523, 10506, 5233, 1524, 2074, 4165, 2919, 12054, 1012]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfbB-UNDOL7f"
      },
      "source": [
        "ここでひっかかる"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUsAcl1EHw3F",
        "outputId": "183d7a48-05f0-4ef5-c293-1dc2cf691344"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in bodys:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        str(sent),                     # Sentence to encode. #ここを書き換えれば解決\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "\n",
        "                        # This function also supports truncation and conversion\n",
        "                        # to pytorch tensors, but we need to do padding, so we\n",
        "                        # can't use these features :( .\n",
        "                        #max_length = 128,          # Truncate all sentences.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', bodys[10])\n",
        "print('Token IDs:', input_ids[10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (636 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  That crowd specifically is probably closer to 0.001% of the population.\n",
            "Token IDs: [101, 2008, 4306, 4919, 2003, 2763, 3553, 2000, 1014, 1012, 25604, 1003, 1997, 1996, 2313, 1012, 102]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdsuPu0-vvfk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13ce2133-38e8-4e6e-b36e-7ad83208b25f"
      },
      "source": [
        "# We'll borrow the `pad_sequences` utility function to do this.\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the maximum sequence length.\n",
        "# I've chosen 64 somewhat arbitrarily. It's slightly larger than the\n",
        "# maximum training sentence length of 47...\n",
        "MAX_LEN = 64\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
        "# as opposed to the beginning.\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Padding/truncating all sentences to 64 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzpunIbLv01M"
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in input_ids:\n",
        "    \n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    \n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38A6GW3kv5cf"
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets for\n",
        "# training\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 90% for training and 10% for validation.\n",
        "train_inputs, validation_inputs, train_subreddits, validation_subreddits = train_test_split(input_ids, subreddits, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, subreddits,\n",
        "                                             random_state=2018, test_size=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLdBvHg8wJQn"
      },
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype \n",
        "# for our model.\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_subreddits = torch.tensor(train_subreddits)\n",
        "validation_subreddits = torch.tensor(validation_subreddits)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIQ1JyFr80-Y"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
        "# 16 or 32.\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_subreddits)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_subreddits)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGPGeiJUVujP",
        "outputId": "c289baf0-a76f-40ef-d246-819259b19282"
      },
      "source": [
        "print(\"length of train data:\",len(train_data))\n",
        "print(\"length of validation data:\",len(validation_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of train data: 9000\n",
            "length of validation data: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GVNU1HErqst",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "33e6f6fbd00f4ce9a1b7c4183e8c5c57",
            "0390a53b662e41ac9dfb156f0373ce92",
            "fcdc854282fb4e86916d33b771cb796e",
            "e8ead906a1724e39b52e8eeac88b538f",
            "4000c65f853644a593a5afdefab0d8e9",
            "bd83fd28aaaf4a36af3e966d759b0112",
            "613412fe4299459cb79e9bd87641ce48",
            "ac317f81380d439b83a47980d27d8af7",
            "5dcb1337d3074bb6ab9862af0390ddac",
            "92e04bb4755749b7a84539cc2194e9a5",
            "054ea5b890594808bb829f45c5ae98c1"
          ]
        },
        "outputId": "6f865a80-5a4a-4d19-fb80-a54043ae8fdc"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "33e6f6fbd00f4ce9a1b7c4183e8c5c57",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGbGAoaKsF3l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de2dc15b-0779-4f7a-9331-cde6b3b22c55"
      },
      "source": [
        "whos"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variable                        Type                             Data/Info\n",
            "--------------------------------------------------------------------------\n",
            "AdamW                           type                             <class 'transformers.optimization.AdamW'>\n",
            "BertConfig                      type                             <class 'transformers.mode<...>uration_bert.BertConfig'>\n",
            "BertForSequenceClassification   type                             <class 'transformers.mode<...>rSequenceClassification'>\n",
            "BertTokenizer                   type                             <class 'transformers.mode<...>tion_bert.BertTokenizer'>\n",
            "DataLoader                      type                             <class 'torch.utils.data.dataloader.DataLoader'>\n",
            "MAX_LEN                         int                              64\n",
            "RandomSampler                   type                             <class 'torch.utils.data.sampler.RandomSampler'>\n",
            "SequentialSampler               type                             <class 'torch.utils.data.<...>mpler.SequentialSampler'>\n",
            "TensorDataset                   type                             <class 'torch.utils.data.dataset.TensorDataset'>\n",
            "att_mask                        list                             n=64\n",
            "attention_masks                 list                             n=10000\n",
            "batch_size                      int                              32\n",
            "bodys                           ndarray                          10000: 10000 elems, type `object`, 80000 bytes\n",
            "count_df                        DataFrame                                      subreddit  <...>         worldnews  25000\n",
            "device                          device                           cuda\n",
            "df                              DataFrame                                subreddit        <...>n[10000 rows x 2 columns]\n",
            "df_0                            DataFrame                                subreddit        <...>n[25000 rows x 2 columns]\n",
            "df_1                            DataFrame                                subreddit        <...>n[25000 rows x 2 columns]\n",
            "discard_0                       DataFrame                                subreddit        <...>n[20000 rows x 2 columns]\n",
            "discard_1                       DataFrame                                subreddit        <...>n[20000 rows x 2 columns]\n",
            "encoded_sent                    list                             n=42\n",
            "input_ids                       ndarray                          10000x64: 640000 elems, type `int64`, 5120000 bytes (4.8828125 Mb)\n",
            "list                            list                             n=2\n",
            "model                           BertForSequenceClassification    BertForSequenceClassifica<...>features=2, bias=True)\\n)\n",
            "pad_sequences                   function                         <function pad_sequences at 0x7f0ed3532c20>\n",
            "pd                              module                           <module 'pandas' from '/u<...>ages/pandas/__init__.py'>\n",
            "sent                            ndarray                          64: 64 elems, type `int64`, 512 bytes\n",
            "split_dataset_0                 DataFrame                                subreddit        <...>\\n[5000 rows x 2 columns]\n",
            "split_dataset_1                 DataFrame                                subreddit        <...>\\n[5000 rows x 2 columns]\n",
            "subreddits                      ndarray                          10000: 10000 elems, type `int64`, 80000 bytes\n",
            "tf                              module                           <module 'tensorflow' from<...>/tensorflow/__init__.py'>\n",
            "tokenizer                       BertTokenizer                    PreTrainedTokenizer(name_<...> 'mask_token': '[MASK]'})\n",
            "torch                           module                           <module 'torch' from '/us<...>kages/torch/__init__.py'>\n",
            "train_data                      TensorDataset                    <torch.utils.data.dataset<...>object at 0x7f0dc666bd90>\n",
            "train_dataloader                DataLoader                       <torch.utils.data.dataloa<...>object at 0x7f0dc666b4d0>\n",
            "train_inputs                    Tensor                           tensor([[  101,  1004, 14<...>.,     0,     0,     0]])\n",
            "train_masks                     Tensor                           tensor([[1, 1, 1,  ..., 1<...>1, 1, 1,  ..., 0, 0, 0]])\n",
            "train_sampler                   RandomSampler                    <torch.utils.data.sampler<...>object at 0x7f0dc666b610>\n",
            "train_subreddits                Tensor                           tensor([1, 0, 0,  ..., 0, 0, 1])\n",
            "train_test_split                function                         <function train_test_split at 0x7f0dc26833b0>\n",
            "validation_data                 TensorDataset                    <torch.utils.data.dataset<...>object at 0x7f0dc666b790>\n",
            "validation_dataloader           DataLoader                       <torch.utils.data.dataloa<...>object at 0x7f0dc666bf90>\n",
            "validation_inputs               Tensor                           tensor([[  101, 14021, 23<...>.,     0,     0,     0]])\n",
            "validation_masks                Tensor                           tensor([[1, 1, 1,  ..., 0<...>1, 1, 1,  ..., 0, 0, 0]])\n",
            "validation_sampler              SequentialSampler                <torch.utils.data.sampler<...>object at 0x7f0dc666b910>\n",
            "validation_subreddits           Tensor                           tensor([1, 0, 0, 0, 1, 1,<...> 1, 1, 1, 1, 1, 1, 1, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5vnKQq1sHuc"
      },
      "source": [
        "del list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXobR03zsHyh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ea75884-df0d-49b9-b1da-516b3feb3065"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQmmZgnesJb0"
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJLAsdgZsL_Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "180dff47-6b59-4e37-a255-e7ea7722cba7"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n",
        "scheduler"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.optim.lr_scheduler.LambdaLR at 0x7f0dc7289990>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMgLdT0LsO8t"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FJbbti9sSNW"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79Z5pm6NsUed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99bd5763-70a3-4064-aa46-cdc01cf34cd8"
      },
      "source": [
        "import random\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 100 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        # The call to `model` always returns a tuple, so we need to pull the \n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.4f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        #print(\"tmp_eval_accuracy\\n\",tmp_eval_accuracy)\n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "        #print(\"eval_accuracy\\n\",eval_accuracy)\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "        #print(\"logits\\n\",logits)\n",
        "        #print(\"label_ids\\n\",label_ids)\n",
        "        #print(\"nb_eval_steps\\n\",nb_eval_steps)\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "\n",
        "\n",
        "    print(\"  Accuracy: {0:.4f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch   100  of    282.    Elapsed: 0:00:21.\n",
            "  Batch   200  of    282.    Elapsed: 0:00:41.\n",
            "\n",
            "  Average training loss: 0.1919\n",
            "  Training epcoh took: 0:00:58\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.7354\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch   100  of    282.    Elapsed: 0:00:21.\n",
            "  Batch   200  of    282.    Elapsed: 0:00:41.\n",
            "\n",
            "  Average training loss: 0.1677\n",
            "  Training epcoh took: 0:00:58\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.7354\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch   100  of    282.    Elapsed: 0:00:20.\n",
            "  Batch   200  of    282.    Elapsed: 0:00:41.\n",
            "\n",
            "  Average training loss: 0.1662\n",
            "  Training epcoh took: 0:00:58\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.7354\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch   100  of    282.    Elapsed: 0:00:20.\n",
            "  Batch   200  of    282.    Elapsed: 0:00:41.\n",
            "\n",
            "  Average training loss: 0.2001\n",
            "  Training epcoh took: 0:00:58\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.7354\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xZzE5GOW221",
        "outputId": "24e4b28c-4ea1-42f6-8d10-e3fdb7b8e4d7"
      },
      "source": [
        "eval_accuracy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23.53125"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OO2vrwnwW8h6",
        "outputId": "5ae36084-e23c-421a-f489-90f699175497"
      },
      "source": [
        "nb_eval_steps"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhr-Lzg_XF1X",
        "outputId": "158ba6d5-285d-4658-dad4-ca1649fe8c71"
      },
      "source": [
        "eval_accuracy/nb_eval_steps"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7353515625"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFK47fx6tjxm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "60398139-c350-40cb-85ee-d52256f03be1"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "#plt.rcParam[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDepN0AbHIef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9475054d-921c-4471-91d6-4e9d0b9fe253"
      },
      "source": [
        "loss_values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.19188531986206558,\n",
              " 0.167697733122829,\n",
              " 0.16616648555805918,\n",
              " 0.20006720852503118]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1alxJ4duxCA0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "c5eaadd0-97f1-412c-8d01-ec2d146cf1a2"
      },
      "source": [
        "import plotly.express as px\n",
        "\n",
        "f = pd.DataFrame(loss_values)\n",
        "f.columns=['Loss']\n",
        "fig = px.line(f, x=f.index, y=f.Loss)\n",
        "fig.update_layout(title='Training loss of the Model',\n",
        "                   xaxis_title='Epoch',\n",
        "                   yaxis_title='Loss')\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"569de539-d56f-4c13-af73-04216cada625\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"569de539-d56f-4c13-af73-04216cada625\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '569de539-d56f-4c13-af73-04216cada625',\n",
              "                        [{\"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"index=%{x}<br>Loss=%{y}\", \"legendgroup\": \"\", \"line\": {\"color\": \"#636efa\", \"dash\": \"solid\"}, \"mode\": \"lines\", \"name\": \"\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [0, 1, 2, 3], \"xaxis\": \"x\", \"y\": [0.19188531986206558, 0.167697733122829, 0.16616648555805918, 0.20006720852503118], \"yaxis\": \"y\"}],\n",
              "                        {\"legend\": {\"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Training loss of the Model\"}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Epoch\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Loss\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('569de539-d56f-4c13-af73-04216cada625');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wELlVP2ZmbEs"
      },
      "source": [
        "test でやってみるのまき\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3FPjAUkmkUa"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTBmN-I0dZbT",
        "outputId": "8c12940c-d52b-4bad-8513-bb13409715e0"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "split_dataset_test_0,discard_test_0=train_test_split(discard_0, train_size=(1000/(25000-5000))) \n",
        "print(\"使えるデータセット\")\n",
        "print(split_dataset_test_0)\n",
        "\n",
        "split_dataset_test_1 ,discard_test_1= train_test_split(discard_1, train_size=(1000/(25000-5000)))\n",
        "print(\"使えるデータセット\")\n",
        "print(split_dataset_test_1)\n",
        "\n",
        "\n",
        "\n",
        "list=[]\n",
        "list.append(split_dataset_test_0)\n",
        "list.append(split_dataset_test_1)\n",
        "\n",
        "\n",
        "\n",
        "df = pd.concat(list, sort=False)\n",
        "print(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "使えるデータセット\n",
            "        subreddit                                               body\n",
            "537529          0  If guns made us less safe, given the number of...\n",
            "765741          0  If you happen to be eating a milkshake you cou...\n",
            "52548           0  [FBI Active shooter study from 2000-2013](http...\n",
            "281312          0  Can we take a moment to thank the officers who...\n",
            "185541          0  I am not sure if we are talking about differen...\n",
            "...           ...                                                ...\n",
            "186452          0  Yeah, for attention. Sadly, the majority of ma...\n",
            "424736          0  I bought my first house (built in 1899, 2 stor...\n",
            "763787          0  What I want to know is amongst all the backlas...\n",
            "563759          0        The wasps have made the first offensive....\n",
            "727172          0  Let’s be wallowing in our own shit when Jesus ...\n",
            "\n",
            "[1000 rows x 2 columns]\n",
            "使えるデータセット\n",
            "        subreddit                                               body\n",
            "232348          1  'WMDs worked with Iraq, why not Venezuela?'\\n\\...\n",
            "511576          1  That's an American problem with 12 hour shifts...\n",
            "319256          1  Except that it wasn't stolen. The article says...\n",
            "347700          1  If US wants to help then lift sanctions. Right...\n",
            "64166           1  Let me know when u find that evidence of Trump...\n",
            "...           ...                                                ...\n",
            "544974          1  He's a petty man-baby who needs everyone to wo...\n",
            "435008          1  ...who is expecting a medal from anything? \\n\\...\n",
            "525458          1  Huh? Nowhere have I mentioned my thoughts on v...\n",
            "670783          1  It takes a long time to say anything in a bure...\n",
            "552520          1  &gt;but I believe he happens to be doing well ...\n",
            "\n",
            "[1000 rows x 2 columns]\n",
            "        subreddit                                               body\n",
            "537529          0  If guns made us less safe, given the number of...\n",
            "765741          0  If you happen to be eating a milkshake you cou...\n",
            "52548           0  [FBI Active shooter study from 2000-2013](http...\n",
            "281312          0  Can we take a moment to thank the officers who...\n",
            "185541          0  I am not sure if we are talking about differen...\n",
            "...           ...                                                ...\n",
            "544974          1  He's a petty man-baby who needs everyone to wo...\n",
            "435008          1  ...who is expecting a medal from anything? \\n\\...\n",
            "525458          1  Huh? Nowhere have I mentioned my thoughts on v...\n",
            "670783          1  It takes a long time to say anything in a bure...\n",
            "552520          1  &gt;but I believe he happens to be doing well ...\n",
            "\n",
            "[2000 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7PuJIGM342n",
        "outputId": "0ecc23b9-33e3-46c8-85ff-ca1a99b03edf"
      },
      "source": [
        "print(df.sample(10))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        subreddit                                               body\n",
            "643871          1  Breaking News: 400 page Mueller report release...\n",
            "668448          0                        Me too. That's why I carry.\n",
            "114181          0  If you can dodge my fist you're ready for the ...\n",
            "7244            1  Venezuelans knows that everything that is goin...\n",
            "544239          0  My dad's a mechanic and I just ask him. Honda'...\n",
            "211600          1  They're probably not once they find out. It's ...\n",
            "216093          1  You know education is free right now right?\\n\\...\n",
            "521583          1  British refer to 'Asia' as the Middle East and...\n",
            "304296          1                        Good \\nThey are shit anyway\n",
            "548879          0  Not really lying to themselves, its way better...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfHQ3AmN342n"
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "subreddits = df.subreddit.values\n",
        "bodys = df.body.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5guwNZIF342n",
        "outputId": "132cef9c-6264-4383-ee81-af7d88217a0a"
      },
      "source": [
        "print(bodys[1:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['If you happen to be eating a milkshake you could make a sacrifice and toss it in their tailgate. A mess to clean up and milk smells real bad once it spoils. Draws flies too.'\n",
            " '[FBI Active shooter study from 2000-2013](http://www.documentcloud.org/documents/1304981-fbi-study-on-mass-shootings.html)\\n\\n[Here’s the picture I am referring to](https://i.imgur.com/SRjJjc4.jpg) \\n\\nOf the 160 active shooter incidents from 2000-2013\\n\\n-\\t25 times the shooter fled before police\\n-\\t37 times the shooter committed suicide\\n-\\t21 times Unarmed Civilians restrained the shooter \\n-\\t5 times an armed non law enforcement entity exchanged fire. 4 of those 5 were security guards.\\n-\\t2 times armed off duty police officers'\n",
            " 'Can we take a moment to thank the officers who risked their lives to stop the shooter? Cops get torn apart on Reddit sometimes but these guys put everything on the line to do their jobs and save lives as quickly as possible. Not all people would or could do the same.'\n",
            " 'I am not sure if we are talking about different things but the ban expired in 2004.'\n",
            " 'I saw a video of military vehicles running over civilians'\n",
            " \"So what's the point? He said exactly that the victim's names should be printed first before the shooter. That should not happen. Saying we shouldn't be printing his name and picture is fine. But that's not what he said.\"\n",
            " 'If you dissolve salt in water you get saltwater. The salt is still there even if the solids are gone. I don’t really know anything about the chemical properties of coke, but I’d imagine it doesn’t just stop being cocaine in the presence of some h2o.'\n",
            " \"please look into it further, don't trust me.\"\n",
            " 'And yet we still look like the wild west compared to the rest of the civilized world.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYwpBh1B342n",
        "outputId": "1341bf5a-c5dc-48c0-8acd-7bc3da93d9b6"
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', bodys[1])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(bodys[1]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(bodys[1])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Original:  If you happen to be eating a milkshake you could make a sacrifice and toss it in their tailgate. A mess to clean up and milk smells real bad once it spoils. Draws flies too.\n",
            "Tokenized:  ['if', 'you', 'happen', 'to', 'be', 'eating', 'a', 'milk', '##sha', '##ke', 'you', 'could', 'make', 'a', 'sacrifice', 'and', 'toss', 'it', 'in', 'their', 'tail', '##gate', '.', 'a', 'mess', 'to', 'clean', 'up', 'and', 'milk', 'smells', 'real', 'bad', 'once', 'it', 'spoil', '##s', '.', 'draws', 'flies', 'too', '.']\n",
            "Token IDs:  [2065, 2017, 4148, 2000, 2022, 5983, 1037, 6501, 7377, 3489, 2017, 2071, 2191, 1037, 8688, 1998, 10055, 2009, 1999, 2037, 5725, 5867, 1012, 1037, 6752, 2000, 4550, 2039, 1998, 6501, 14747, 2613, 2919, 2320, 2009, 27594, 2015, 1012, 9891, 10029, 2205, 1012]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFwF6uHz342n",
        "outputId": "64752128-eba4-43a4-8261-3cb266437fa4"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in bodys:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        str(sent),                     # Sentence to encode. #ここを書き換えれば解決\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "\n",
        "                        # This function also supports truncation and conversion\n",
        "                        # to pytorch tensors, but we need to do padding, so we\n",
        "                        # can't use these features :( .\n",
        "                        #max_length = 128,          # Truncate all sentences.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', bodys[10])\n",
        "print('Token IDs:', input_ids[10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  Here is a related patent by Jeffrey John Hastings of Naturo:\n",
            "\n",
            "&amp;#x200B;\n",
            "\n",
            "[A Process For Treating Milk](https://patents.google.com/patent/AU2017101661A4/en?inventor=Jeffrey+John+Hastings)\n",
            "Token IDs: [101, 2182, 2003, 1037, 3141, 7353, 2011, 10799, 2198, 12296, 1997, 14085, 10976, 1024, 1004, 23713, 1025, 1001, 1060, 28332, 2497, 1025, 1031, 1037, 2832, 2005, 12318, 6501, 1033, 1006, 16770, 1024, 1013, 1013, 13979, 1012, 8224, 1012, 4012, 1013, 7353, 1013, 8740, 11387, 16576, 10790, 16048, 2575, 2487, 2050, 2549, 1013, 4372, 1029, 12235, 1027, 10799, 1009, 2198, 1009, 12296, 1007, 102]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vfBNknB342n",
        "outputId": "679952db-f964-4e75-dbd5-70a4393782d4"
      },
      "source": [
        "# We'll borrow the `pad_sequences` utility function to do this.\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the maximum sequence length.\n",
        "# I've chosen 64 somewhat arbitrarily. It's slightly larger than the\n",
        "# maximum training sentence length of 47...\n",
        "MAX_LEN = 64\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
        "# as opposed to the beginning.\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Padding/truncating all sentences to 64 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0xTR0ur342n"
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in input_ids:\n",
        "    \n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    \n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xkHGueVUWa-"
      },
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "test_inputs=input_ids\n",
        "test_subreddits=subreddits\n",
        "test_masks=attention_masks\n",
        "#, discard_inputs, test_subreddits, discard_subreddits = train_test_split(input_ids, subreddits, \n",
        "                                                         #   random_state=2018, test_size=0.9)\n",
        "# Do the same for the masks.\n",
        "#test_masks, discard_masks, _, _ = train_test_split(attention_masks, subreddits,\n",
        "                                #             random_state=2018, test_size=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcBvuNdyUWa_"
      },
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype \n",
        "# for our model.\n",
        "test_inputs = torch.tensor(test_inputs)\n",
        "\n",
        "\n",
        "test_subreddits = torch.tensor(test_subreddits)\n",
        "\n",
        "\n",
        "test_masks = torch.tensor(test_masks)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_HT2vZA9MiQ"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
        "# 16 or 32.\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_subreddits)\n",
        "test_sampler = RandomSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgUaHNRt3qa6"
      },
      "source": [
        "test_data = TensorDataset(test_inputs, test_masks, test_subreddits)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyKPEEo36tw0",
        "outputId": "1646efac-2256-427f-bcca-4417eec10113"
      },
      "source": [
        "len(test_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Va3RI1mn7yM"
      },
      "source": [
        "#試行錯誤の記録\n",
        "#import torch\n",
        "#torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "\n",
        "#model = model.to('cuda:0')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NV-eVNIql9C",
        "outputId": "e57a92c2-ab60-4816-f5d0-bf5faf3fc85a"
      },
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G20kBKPKqyAj",
        "outputId": "e40cb1e9-5efe-4ae3-ee7b-3a22d0e3240b"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIh7osycmZJr",
        "outputId": "1919f1c8-2d90-41a1-dc78-8c7f516d1e20"
      },
      "source": [
        "t0 = time.time()\n",
        "\n",
        "for batch in validation_dataloader:\n",
        "\n",
        "    b_input_ids =test_inputs\n",
        "    #print(\"***********************\\n\")\n",
        "    #print(\"b_input_ids\\n\",b_input_ids)\n",
        "    #print(\"length of b_input_ids:\",len(b_input_ids))\n",
        "    b_input_mask = test_masks\n",
        "    #print(\"***********************\\n\")\n",
        "    #print(\"b_input_mask\",b_input_mask)\n",
        "    #print(\"length of b_input_mask:\",len(b_input_mask))    \n",
        "    b_labels = test_subreddits\n",
        "    #print(\"***********************\\n\")\n",
        "    #print(\"b_labels\\n\",b_labels)\n",
        "\n",
        "    b_input_ids = b_input_ids.to(device)\n",
        "    b_input_mask = b_input_mask.to(device)\n",
        "    b_labels = b_labels.to(device)\n",
        "    \n",
        "    with torch.no_grad():   \n",
        "        # 学習済みモデルによる予測結果をpredsで取得     \n",
        "      preds = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        #print(\"***********************\\n\")\n",
        "        #print(\"preds\\n\",preds)\n",
        "\n",
        "#print(b_input_ids)\n",
        "#print(\"b_labels\\n\",b_labels)\n",
        "print(\"preds\\n\",preds)\n",
        "print(\"time took : {:}\".format(format_time(time.time() - t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "preds\n",
            " SequenceClassifierOutput(loss=None, logits=tensor([[ 1.4457, -1.9207],\n",
            "        [ 0.8215, -1.0780],\n",
            "        [ 1.7360, -2.1562],\n",
            "        ...,\n",
            "        [-1.6142,  1.3998],\n",
            "        [-1.7144,  1.7630],\n",
            "        [-1.6848,  1.4660]], device='cuda:0'), hidden_states=None, attentions=None)\n",
            "time took : 0:01:50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "wLTnxlUmsPbl",
        "outputId": "9408fe1a-2bf4-48d0-ec50-da7502e60185"
      },
      "source": [
        "# 比較しやすい様にpd.dataframeへ整形\n",
        "import pandas as pd\n",
        "\n",
        "# pd.dataframeへ変換（GPUに乗っているTensorはgpu->cpu->numpy->dataframeと変換）\n",
        "logits_df = pd.DataFrame(preds[0].cpu().numpy() )\n",
        "## np.argmaxで大き方の値を取得\n",
        "pred_df = pd.DataFrame(np.argmax(preds[0].cpu().numpy(), axis=1), columns=['pred_label'])\n",
        "label_df = pd.DataFrame(b_labels.cpu().numpy(), columns=['true_label'])\n",
        "\n",
        "accuracy_df = pd.concat([logits_df, pred_df, label_df], axis=1)\n",
        "\n",
        "accuracy_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>pred_label</th>\n",
              "      <th>true_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.445704</td>\n",
              "      <td>-1.920667</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.821499</td>\n",
              "      <td>-1.077996</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.735954</td>\n",
              "      <td>-2.156158</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.912337</td>\n",
              "      <td>-2.398357</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.034320</td>\n",
              "      <td>-2.458689</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>-1.395449</td>\n",
              "      <td>1.289915</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>-0.318608</td>\n",
              "      <td>-0.022783</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>-1.614221</td>\n",
              "      <td>1.399780</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>-1.714411</td>\n",
              "      <td>1.762963</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>-1.684798</td>\n",
              "      <td>1.465986</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             0         1  pred_label  true_label\n",
              "0     1.445704 -1.920667           0           0\n",
              "1     0.821499 -1.077996           0           0\n",
              "2     1.735954 -2.156158           0           0\n",
              "3     1.912337 -2.398357           0           0\n",
              "4     2.034320 -2.458689           0           0\n",
              "...        ...       ...         ...         ...\n",
              "1995 -1.395449  1.289915           1           1\n",
              "1996 -0.318608 -0.022783           1           1\n",
              "1997 -1.614221  1.399780           1           1\n",
              "1998 -1.714411  1.762963           1           1\n",
              "1999 -1.684798  1.465986           1           1\n",
              "\n",
              "[2000 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "67oSJwJzPJZo",
        "outputId": "10171f3f-5012-43e3-cb32-23db7fd1cb8b"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cmatrix = confusion_matrix(label_df,pred_df)\n",
        "print(cmatrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4776c0332dba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'label_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "kU4_9ymEwccX",
        "outputId": "6451004c-4714-4dae-840f-9aacb0578b73"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.title(\"low cos similality 2 classes\")\n",
        "plt.rcParams[\"font.size\"] = 20\n",
        "sns.heatmap(df, cmap= sns.color_palette('rainbow', 50), annot=True,fmt='.0f',vmin=0,vmax=1000)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0dc892a890>"
            ]
          },
          "metadata": {},
          "execution_count": 87
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkgAAAJQCAYAAAB1m5tZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3daXxU1cHH8X/2fSCBBEjYIwQMRMBW1ioCakLZgixK2YoF6gMUUGuh2kWrlQJV0UhF6hIspYiCAYSgQK3aIpYtKRoRYlhkyyCSMAnJZJnnRZqpcyaQCGOG4O/7qjn33DtnPjXMj7sMPg6HwyEAAAA4+Xp7AQAAAFcbAgkAAMBAIAEAABgIJAAAAAOBBAAAYCCQAAAADAQSAACAgUACAABelZ2drUceeUSDBw9Wt27d1L9/f82dO1dHjhxxm7tnzx7dfffduuGGG9S3b1899thjunDhgts8u92uRYsWqV+/fkpKStKYMWO0Y8eOOq/Jhy+KBAAA3vSzn/1Me/bsUXJyshISEmS1WrVy5UoVFxfr9ddfV3x8vCQpJydHY8eO1XXXXafRo0fr1KlTeumll9S3b189//zzLse877779Pbbb2vixIlq06aN1q1bp/379+vVV19V9+7da10TgQQAALxqz5496tKliwIDA51jhw8f1tChQ/XDH/5QCxYskCRNnTpVBw4c0ObNmxUWFiZJWrNmjR5++GG98sor6t27t6SqM1KjR4/W/PnzNXnyZElSaWmphgwZopiYGK1cubLWNXGJDQAAeFWPHj1c4kiS2rZtqw4dOig3N1eSZLPZ9K9//UsjRoxwxpEkDR8+XKGhodq8ebNzLDMzUwEBARo9erRzLCgoSKNGjdLu3buVn59f65oIJAAAcNVxOBw6c+aMIiMjJUkHDhxQeXm5unTp4jIvMDBQnTt3Vk5OjnMsJydH7dq1cwkpSUpKSpLD4XCZezH+HngPAAAALgoLC1VYWOg2brFYZLFYat1//fr1On36tObOnStJslqtkqTo6Gi3udHR0dq3b5/zZ6vVqmbNmtU4T1KdziBdVYFks0/39hIAAKg34YHL6vX16vNzNj29i9LS0tzGZ86cqVmzZl1y39zcXD366KO68cYbNXz4cElSSUmJJLldipOqLp9Vb6+eGxAQUOM8qep+pNpcVYEEAACuDZMmTVJqaqrbeG1nj6xWq6ZPn65GjRppyZIl8vWtuhsoODhYUtXj+6bS0lLn9uq5ZWVlNc6T/hdKl0IgAQAAj6vrpbSvO3/+vKZOnarz589r1apVLpfTqv939aW2r7NarYqJiXGZW9NltOp9vz73YrhJGwAAeF1paal++tOf6vDhw1q2bJnat2/vsr1jx47y9/fX/v37XcbtdrtycnLUuXNn51inTp2Ul5enoqIil7lZWVnO7bUhkAAAgFdVVFRozpw52rdvn5YsWaJu3bq5zYmIiFDv3r2VkZHhEj4ZGRkqLi5WcnKycyw5OVllZWVas2aNc8xut2vt2rXq0aNHjTdwm7jEBgAAvGrBggXavn27br31Vp07d04ZGRnObWFhYRo0aJAkae7cubrrrrs0YcIE5zdpv/zyy7r55pvVp08f5z433HCDkpOTtXjxYlmtVrVu3Vrr1q3TiRMn9MQTT9RpTVfVN2nzFBsA4LvkWn6K7Zu8twkTJuijjz6qcVtcXJy2b9/u/HnXrl1avHixPvnkE4WHh2vw4MG67777FBoa6rJfaWmpnn76aW3YsEEFBQVKSEjQfffd5xJSl0IgAQDgJQTS1Yt7kAAAAAwEEgAAgIFAAgAAMBBIAAAABgIJAADAQCABAAAYCCQAAAADgQQAAGAgkAAAAAwEEgAAgIFAAgAAMBBIAAAABgIJAADAQCABAAAYCCQAAAADgQQAAGAgkAAAAAwEEgAAgIFAAgAAMPh7ewEAAKB+2Oz191rhgfX3Wt8GziABAAAYCCQAAAADgQQAAGAgkAAAAAwEEgAAgIFAAgAAMBBIAAAABgIJAADAQCABAAAYCCQAAAADgQQAAGAgkAAAAAwEEgAAgIFAAgAAMBBIAAAABgIJAADAQCABAAAYCCQAAAADgQQAAGAgkAAAAAwEEgAAgIFAAgAAMBBIAAAABgIJAADAQCABAAAYCCQAAAADgQQAAGDw9/YCAABA/bDZvb2ChoMzSAAAAAYCCQAAwEAgAQAAGAgkAAAAA4EEAABgIJAAAAAMPOYPAAC8Kj8/XytWrFBWVpb279+v4uJirVixQj179nTO2blzpyZOnHjRY8yZM0f33nuvJGnt2rWaP39+jfOys7MVFBRU65oIJAAA4FV5eXlavny52rRpo4SEBO3du9dtTnx8vBYuXOg2vn79en3wwQfq27ev27a5c+eqRYsWLmMBAQF1WhOBBAAAvCoxMVEffvihIiMjtXXrVs2YMcNtTtOmTTV8+HC38eeee05t27ZVUlKS27ZbbrlFnTt3vqw1cQ8SAADwqvDwcEVGRn7j/bKzs3XkyBENHTr0onNsNpsqKyu/8bE5gwQAABqk9evXS9JFA2ncuHEqLi5WUFCQ+vfvr3nz5ik2NrZOxyaQAACAxxUWFqqwsNBt3GKxyGKxXPHxKyoqtHnzZiUlJalNmzYu20JCQjRy5Ej17NlTYWFhysrKUnp6urKysrRu3TpFRUXVenwCCQAAeFx6errS0tLcxmfOnKlZs2Zd8fF37NihM2fOaPr06W7bUlJSlJKS4vz5tttu0/e//31NmzZN6enpmjt3bq3HJ5AAAIDHTZo0SampqW7jnjh7JEkbNmyQn5+fBg8eXKf5t9xyi9q3b68dO3YQSAAAwDs8dSmtJiUlJXrnnXfUu3dvNW3atM77tWjRQsePH6/TXJ5iAwAADcr27dtVVFR0yafXanLs2LE6Py1HIAEAgAZlw4YNCgkJ0W233Vbj9rNnz9a4z9GjR9WvX786vQaX2AAAgNctXbpUkpSbmytJysjI0O7du2WxWDR+/HjnvHPnzun999/X7bffrrCwsBqPdddddykxMVHXX3+9wsPDlZ2drTfffFNt27bVpEmT6rQeAgkAAHjdkiVLXH5+4403JElxcXEugZSZmamysjINGTLkosdKSUnRu+++q/fff18lJSWKiYnRj370I82cOVMRERF1Wo+Pw+FwXMb7+FbY7O6P6gEAcK0KD1xWr6936Gz9fc5eF1W/783TuAcJAADAQCABAAAYCCQAAAADgQQAAGAgkAAAAAwEEgAAgIHvQQIA4DvCZvf2ChoOziABAAAYCCQAAAADgQQAAGAgkAAAAAwEEgAAgIFAAgAAMBBIAAAABgIJAADAQCABAAAYCCQAAAADgQQAAGAgkAAAAAwEEgAAgIFAAgAAMBBIAAAABgIJAADAQCABAAAYCCQAAAADgQQAAGAgkAAAAAwEEgAAgIFAAgAAMBBIAAAABgIJAADAQCABAAAYCCQAAACDv7cXAAAA6ofN7u0VNBycQQIAADAQSAAAAAYCCQAAwEAgAQAAGAgkAAAAA4EEAABgIJAAAAAMBBIAAICBQAIAADAQSAAAAAYCCQAAwEAgAQAAGAgkAAAAA4EEAABgIJAAAAAMBBIAAICBQAIAADAQSAAAAAZ/by8AV49lS/P0wp+OXHS7n7+PPtp7S43b1qw+rgWPHZQkbX2vjyIjA93mFBSU6aXlR/Tu9jPKP12q0DB/xV8XpntntFX3Gxt75k0ADdCRw8XatPG0PtxxVl8cK5G9tFItWwVr0O0xGje+pUJC/ZxzL/V7Ovv+9po4ufVFX+fChQqNTf23jh8v0Zi7YvWLhzp6/L0A1woCCU4DBkarVasQt/GDB4u04uVjuvmWJjXuZ80v1bNPf67QUD8VF1fUOOfkiRJNm7JPxcUVGp7aXG3ahsp2vlwHPytSfn6pR98H0NBkrDupNX87oZv7N1HK4GbyD/DRro/OaemzeXpnS75eWdlDwcF+Lvvc/2C8GjcOcBnrnBhxydd5/rk8ffVVmcfXD1yLCCQ4dUgIV4eEcLfxxx85IEkaPrJFjfstePygWrYKUXx8mDZtPF3jnIfn56ii3KG/vfE9RUcHeW7RwDVg0O3R+vFP2igi4n9/JI8aE6fWrT/Xi8uPKmPtSY0d19Jln/4Dmio2zv0vNBeT88l5rfrLF/rZ3Hg9tTjXY2sHPCE/P18rVqxQVlaW9u/fr+LiYq1YsUI9e/Z0mTdgwAAdP37cbf+pU6fqgQcecBkrLCzUokWL9M4776ikpERJSUmaP3++OnfuXKc1EUi4pAvFFdqSma9mzYLUp2+U2/bt26x6790zevkvPbTmb+7/0UrSnl3ntG9PgX4+7zpFRweprKxS5eUOhYT41Tgf+K65PtFS4/htyTF6cflR5R4qqnG7zVau4GBf+ftf+nbSigqHHvvtAfXuG6UBg5oSSLjq5OXlafny5WrTpo0SEhK0d+/ei85NTEzUpEmTXMY6dnS9XFxZWalp06bps88+05QpUxQZGam//vWvmjBhgtauXavWrS9+KboagYRLeuftfBXZKnTXuJby8/Nx2WazlWvh7w9q5OhYdelquWggffD+l5Kk5i2CNWfmf/SvD75URYXUuk2Ipk5vo8FDm3/r7wNoiPJPV11+jmrifk/fXXfuUlFRhfz8pMQuFv1kehv1/UHNl8FXvnpMhw8Xa9FTid/qeoHLlZiYqA8//FCRkZHaunWrZsyYcdG5zZs31/Dhwy95vMzMTO3du1fPPfecBg0aJElKSUnRHXfcobS0NC1cuLDWNX2jQDpz5oxycnKUn5+vkpISBQcHKyYmRp06dVJ0dPQ3ORQaiIx1p+TjIw1PdY+YZ576XJWV0szZ7S95jCOHL0iSHnvkgFq3DtFvH+us8rJK/WXFMf3ql5+qvNyhYak1X74DvqsqKhz687Ij8vP3UfLgZs7xiAh/jRzVQkndGsli8deRw8X661++0OwZ/9GvH03QsBGuv0vHv7igZUsPa+r0toqNC9GJ4xfq+60AtQoPd7+941LsdrsqKioUElLzZeYtW7YoJiZGAwcOdI5FRUUpJSVFGzduVFlZmQICAmrct1qdAikrK0uLFy/W7t275XA45HA4XLb7+Pjoxhtv1AMPPKBu3brV5ZBoAA7nFWvfngLd1LOx4lq6/ke4b2+B1q45occWdHa5b6ImxUXlkqTQUD8te6mbAgKqLgf0H9BUw1J2Ku2ZPA0Z3ly+vj6XOgzwnfLHPxxSdlahZsxup7btQp3j4ya0cps7LLWFxqT+W08uzNWg26MVGvq/38nf/+4zxcWF6EcTW7rtBzRE//znP9WtWzdVVFSoVatWmjp1qsaOHesyJycnR4mJifLxcf1c6dq1q1avXq2jR48qPj7+kq9TayDt2LFDU6dOVWxsrObMmaOuXbsqJiZGgYGBstvtys/PV1ZWltatW6cJEyZo+fLl6tWr12W8ZVxtMtadlCSNuNP1b6RlZZV6/JEDuqlXpMvfbC8m6L9P3ySnxDjjSJIsjQJ0861N9Nb60zpyuFjt2od5cPVAw7X02TytXnVcI0e10JSftKl1fuPGARo1JlbLlh5W1r5C9e5Tdb/gpg2ntHPHV1r+SjeX3z2gPhQWFqqwsNBt3GKxyGKp+b672nTs2FHf+9731LZtW3311Vd67bXX9Otf/1oFBQWaNm2ac57Vaq2xRWJiYiRV3RR+xYH09NNPq2vXrkpPT1dgoPt18Pj4ePXu3VtTpkzRxIkT9eSTT+q1116r9U3i6lZeXqm31p9So8b+unWg6+XT11Yd1+G8Ys19IF7HjhY7x6sf8T9xvERFtgq1/O9XBsQ0q3pqrUlT9/9+mv53rLCw/Ft5H0BDs2xpnl584YiGjWiuX/667t9T1CI2WJJ07r+P8dvtlXpyca76/iBKTZsGOn9X80/bJUk2W4WOHS1W48YBirBc+lIDrh3n7fX3Wunp6UpLS3MbnzlzpmbNmnVZx3z++eddfh45cqTGjRunpUuX6u6771ZERNVXXZSUlNTYLNVjJSUltb5WrYH06aef6uGHH67xhcwXHTlypB5//PFaXxRXv/f+8aW+/LJMd4+PU2Cg6988T54sUWWlNOve/9S478S79ygkxFcffHSzJKlLlwi98Zp0+rT79x05b0KN4g9ooPpLIIcMa6ZfPZLgdnngUo4dqQqgJv+9obu0pEJfnS3TB++d1QfvfeQ2f9PG09q08XStXy4JXK5JkyYpNTXVbfxyzx7VxM/PT5MmTdLcuXO1d+9e3Xxz1edOcHCw7Hb3GqweCw4OrvXYtQaSxWLR0aNH67TQo0ePevSNw3sy1lZdXhtew83Tw0a0ULfujdzGX/vbCe3+9zn95tEERVj+959W/wFNtfgPh7R542n9ZHob5/0RVmup3t1+Rm3ahqhV61C34wHfJS/86bBe+NMR/XBoM/3md51qvCevvLxSFy5Uut33d+pUiV5/7YQaNfZXUreqP4ODQ/z0hz9e73aMr74q04LHDqpP3ygNH9lcHTp+s5tjgbq6kktp30Tz5lUPERUUFDjHoqOjlZ+f7za3eqz6Utul1BpIw4YN0yuvvKKYmBiNGjWqxjvGL1y4oDVr1ig9PV0TJ06s9UVxdbPml2rHP88qsWtEjX94dkwIV8cavlDy/X9UPc7/g/5NXP6pEUujAM25P16PP/qZJv9oj4aNaKGyskq9/toJlZU59PP5Hb69NwM0AK+tOq5lSw+reYsg3dQrUplvuX7halSTQPXqE6ULxRUamrxT/Qc0Vbv2oYr471Nsb649qQvFFXr8D9c7v3E7IMBXg253/xCofoqt+p8yARq6Y8eOSap6Sq1ap06dtHfvXjkcDpczsdnZ2QoNDfXM9yDNnj1bJ0+e1OOPP66FCxeqffv2io6Odt6kbbVa9fnnn6usrEzJycmaPXv25bw/XEU2ZJxSRYU04iLfnH05Ro6OVePIAKW/fFR/ei5Pvj4+6nqDRY//4foaz0YB3yUf76+6kfXUyVL95qFP3bbf+L1G6tUnSkHBfhpwW1Ptzz6vd7efUfGFCjVuHKCevSI18cet1aUrZ/Bx7Tp37pwsFot8ff9320dpaalefPFFhYWFuTxFn5ycrC1btmjbtm3O70E6e/asMjMzNXDgwFof8ZckH4f5zP5FZGdnKzMzU59++qmsVqvze5Cio6PVqVMnJScnKykp6Zu+Xxc2+/Qr2h8AgIYkPHBZvb7e5kP19zmbct03e29Lly6VJOXm5mrjxo2688471bJlS1ksFo0fP15r167V888/rzvuuENxcXE6d+6c1q1bp8OHD+u3v/2t7r77buexKioqNG7cOB08eND5TdqrVq3SyZMntXbtWrVpU/vToXUOpPpAIAEAvksIpP9JSEiocTwuLk7bt2/X/v37lZaWpk8++URnz55VYGCgEhMTNWXKFN16661u+xUUFGjhwoXaunWrSktL1bVrV82bN0+JiXX7RnkCCQAALyGQrl58cxgAAICBQAIAADAQSAAAAAYCCQAAwEAgAQAAGAgkAAAAA4EEAABgIJAAAAAMBBIAAICBQAIAADAQSAAAAAYCCQAAwEAgAQAAGAgkAAAAA4EEAABgIJAAAAAMBBIAAICBQAIAADAQSAAAAAZ/by8AAADUD1upt1fQcHAGCQAAwEAgAQAAGAgkAAAAA4EEAABgIJAAAAAMBBIAAICBQAIAADAQSAAAAAYCCQAAwEAgAQAAGAgkAAAAA4EEAABgIJAAAAAMBBIAAICBQAIAADAQSAAAAAYCCQAAwEAgAQAAGAgkAAAAA4EEAABgIJAAAAAMBBIAAICBQAIAADAQSAAAAAYCCQAAwEAgAQAAGPy9vQAAAFA/bGXeXkHDwRkkAAAAA4EEAABgIJAAAAAMBBIAAICBQAIAADAQSAAAAAYCCQAAwMD3IAEAAK/Kz8/XihUrlJWVpf3796u4uFgrVqxQz549nXO++uorvfHGG9q+fbs+//xzlZeXKz4+XpMnT1ZKSorL8dauXav58+fX+FrZ2dkKCgqqdU0EEgAA8Kq8vDwtX75cbdq0UUJCgvbu3es2Z9++fXr66ad18803695775W/v7+2bNmiOXPm6PPPP9eMGTPc9pk7d65atGjhMhYQEFCnNRFIAADAqxITE/Xhhx8qMjJSW7durTF2rrvuOm3ZskVxcXHOsXHjxmny5Ml64YUXdM899yg4ONhln1tuuUWdO3e+rDVxDxIAAPCq8PBwRUZGXnJOq1atXOJIknx8fDRo0CCVlJTo+PHjNe5ns9lUWVn5jdfEGSQAANBgnTlzRpJqDKxx48apuLhYQUFB6t+/v+bNm6fY2Ng6HZdAAgAAHldYWKjCwkK3cYvFIovF4pHXOHfunNasWaObbrpJUVFRzvGQkBCNHDlSPXv2VFhYmLKyspSenq6srCytW7fOZe7FEEgAAMDj0tPTlZaW5jY+c+ZMzZo164qPX1lZqQceeEDnz5/Xww8/7LItJSXF5cm22267Td///vc1bdo0paena+7cubUen0ACAAAeN2nSJKWmprqNe+rs0e9+9zt98MEHWrx4sRISEmqdf8stt6h9+/basWMHgQQAALzDk5fSTGlpafrrX/+qBx98UEOGDKnzfi1atLjozdwmnmIDAAANxsqVK/Xss89q8uTJuueee77RvseOHav1ablqBBIAAGgQNm3apMcee0xDhw7VvHnzLjrv7NmzbmMbNmzQ0aNH1a9fvzq9FpfYAACA1y1dulSSlJubK0nKyMjQ7t27ZbFYNH78eGVnZ+vBBx9U48aN1bt3b61fv95l/759+6pp06aSpLvuukuJiYm6/vrrFR4eruzsbL355ptq27atJk2aVKf1EEgAAMDrlixZ4vLzG2+8IUmKi4vT+PHjdejQIZWVlens2bP65S9/6bb/ihUrnIGUkpKid999V++//75KSkoUExOjH/3oR5o5c6YiIiLqtB4fh8PhuML35DE2+3RvLwEAgHoTHrisXl/v5X319zn74271+948jXuQAAAADAQSAACAgUACAAAwEEgAAAAGAgkAAMBAIAEAABj4HiQAAL4jbHZvr6Dh4AwSAACAgUACAAAwEEgAAAAGAgkAAMBAIAEAABgIJAAAAAOBBAAAYCCQAAAADAQSAACAgUACAAAwEEgAAAAGAgkAAMBAIAEAABgIJAAAAAOBBAAAYCCQAAAADAQSAACAgUACAAAwEEgAAAAGAgkAAMBAIAEAABgIJAAAAAOBBAAAYCCQAAAADAQSAACAgUACAAAw+Ht7AQAAoH7Y7N5eQcPBGSQAAAADgQQAAGAgkAAAAAwEEgAAgIFAAgAAMBBIAAAABgIJAADAQCABAAAYCCQAAAADgQQAAGAgkAAAAAwEEgAAgIFAAgAAMBBIAAAABgIJAADAQCABAAAYCCQAAAADgQQAAGAgkAAAAAwEEgAAgIFAAgAAXpWfn6/FixdrwoQJ6t69uxISErRz584a527btk2pqanq2rWr+vfvr7S0NJWXl7vNKyws1K9+9Sv16tVL3bp108SJE5WTk1PnNRFIAADAq/Ly8rR8+XKdPn1aCQkJF533j3/8QzNmzFCjRo30q1/9SoMGDdJzzz2nJ554wmVeZWWlpk2bprfeekvjx4/Xz3/+c3355ZeaMGGCjh49Wqc1+V/ROwIAALhCiYmJ+vDDDxUZGamtW7dqxowZNc5buHChrr/+er344ovy8/OTJIWFhemFF17QhAkT1LZtW0lSZmam9u7dq+eee06DBg2SJKWkpOiOO+5QWlqaFi5cWOuaOIMEAAC8Kjw8XJGRkZecc+jQIR06dEhjx451xpEkjRs3TpWVlXr77bedY1u2bFFMTIwGDhzoHIuKilJKSoq2bt2qsrKyWtfEGSQAAOBxhYWFKiwsdBu3WCyyWCzf+HiffPKJJKlLly4u482aNVPz5s2d2yUpJydHiYmJ8vHxcZnbtWtXrV69WkePHlV8fPwlX49AAgAAHpeenq60tDS38ZkzZ2rWrFnf+HhWq1WSFB0d7bYtOjpa+fn5LnN79erlNi8mJkZS1U3hBBIAAJAknS+tv9eaMWmSUlNT3cYv5+yRJJWUlEiSAgMD3bYFBQXpwoULLnNrmlc9Vn2sSyGQAACAx13upbSLCQ4OliTZ7Xa3baWlpc7t1XNrmlc99vW5F8NN2gAA4KpXfWmt+lLb11mtVufls+q5X7/kVq167OtzL4ZAAgAAV73OnTtLkvbv3+8yfvr0aZ06dcq5XZI6deqkjz/+WA6Hw2Vudna2QkND1bp161pfj0ACAABXvQ4dOqh9+/ZavXq1KioqnOOrVq2Sr6+vbr/9dudYcnKy8vPztW3bNufY2bNnlZmZqYEDByogIKDW1+MeJAAA4HVLly6VJOXm5kqSMjIytHv3blksFo0fP16S9OCDD+ree+/VPffco8GDB+uzzz7TypUrNXbsWLVr1855rDvuuEPdunXTgw8+qClTpigyMlKrVq1SZWVlnZ+g83GY55+8yGaf7u0lAABQb8IDl9Xr6/1yW/19zv5+4Dd7bxf7J0bi4uK0fft2589bt25VWlqacnNzFRUVpTvvvFP/93//J39/13M+BQUFWrhwobZu3arS0lJ17dpV8+bNU2JiYp3WQyABAOAlBNLVi3uQAAAADAQSAACAgUACAAAwEEgAAAAGAgkAAMBAIAEAABgIJAAAAAOBBAAAYCCQAAAADAQSAACAgUACAAAwEEgAAAAGAgkAAMBAIAEAABgIJAAAAAOBBAAAYCCQAAAADAQSAACAgUACAAAw+Ht7AQAAoH7Y7N5eQcPBGSQAAAADgQQAAGAgkAAAAAwEEgAAgIFAAgAAMBBIAAAABgIJAADAQCABAAAYCCQAAAADgQQAAGAgkAAAAAwEEgAAgIFAAgAAMBBIAAAABgIJAADAQCABAAAYCCQAAAADgQQAAGAgkAAAAAwEEgAAgIFAAgAAMBBIAAAABgIJAADAQCABAAAYCCQAAAADgQQAAGDw9/YCAABA/bDZvb2ChoMzSAAAAAYCCQAAwEAgAQAAGAgkAAAAA4EEAABgIJAAAAAMBBIAAICB70ECAABeNW/ePK1bt8cM9VgAABa4SURBVO6i29977z01a9ZMEyZM0EcffeS2ffDgwXrqqac8uiYCCQAAeNXYsWPVu3dvlzGHw6Hf/va3iouLU7NmzZzjsbGxmjNnjsvcuLg4j6+JQAIAAF7VvXt3de/e3WVs165dunDhgoYOHeoybrFYNHz48G99TdyDBAAArjobN26Uj4+PhgwZ4ratvLxcRUVF3+rrcwYJAAB4XGFhoQoLC93GLRaLLBbLJfctKyvT5s2b1b17d7Vs2dJlW25urrp166aysjJFR0dr/PjxmjZtmnx9PXvOh0ACAAAel56errS0NLfxmTNnatasWZfc94MPPtC5c+fcLq+1atVKPXv2VEJCgmw2mzZu3KinnnpKJ06c0KOPPurR9fs4HA6HR494BWz26d5eAgAA9SY8cFm9vt6UjPr7nH361kWXfQbp/vvv15YtW/T+++8rMjLyknNnz56tLVu2aNOmTWrfvv0VrfnrOIMEAAA8ri4hVJOioiJt27ZN/fr1qzWOJGnKlCnKzMzUzp07PRpI3KQNAACuGlu3bq3x6bWLad68uSSpoKDAo+sgkAAAwFVjw4YNCg0N1YABA+o0/9ixY5KkqKgoj66DQAIAAFeFs2fPaseOHbrtttsUEhLiss1ms8lut7uMVVRUaNmyZfL19XX7oskrxT1IAADgqrBp0yaVl5fXeHnt448/1v33368hQ4aodevWKi4u1ubNm7V//35NnTpVrVq18uhaCCQAAHBV2LBhg5o0aaI+ffq4bYuNjVWPHj309ttv68yZM/L19VWHDh20YMECpaamenwtBBIAALgqrF69+qLbWrVqpWeeeabe1sI9SAAAAAYCCQAAwEAgAQAAGAgkAAAAA4EEAABgIJAAAAAMPOYPAMB3hM1e+xxU4QwSAACAgUACAAAwEEgAAAAGAgkAAMBAIAEAABgIJAAAAAOBBAAAYCCQAAAADAQSAACAgUACAAAwEEgAAAAGAgkAAMBAIAEAABgIJAAAAAOBBAAAYCCQAAAADAQSAACAgUACAAAwEEgAAAAGAgkAAMBAIAEAABgIJAAAAAOBBAAAYCCQAAAADAQSAACAgUACAAAw+Ht7AQAAoH7Y7N5eQcPBGSQAAAADgQQAAGAgkAAAAAwEEgAAgIFAAgAAMBBIAAAABgIJAADAQCABAAAYCCQAAAADgQQAAGAgkAAAAAwEEgAAgIFAAgAAMBBIAAAABgIJAADAQCABAAAYCCQAAAADgQQAAGDw9/YCcHU4crhYmzae1oc7zuqLYyWyl1aqZatgDbo9RuPGt1RIqJ9z7rKleXrhT0dqPM7s+9tr4uTWLmNfnrFr2dI8ffDeWX35pV1Nmgbq1oFN9dP/a6sIS8C3+r6AhuBSv1OS5Ofvo4/23lLjtjWrj2vBYwclSVvf66PIyECX7S/9+Yg+/cSmTz85r+PHS9QiNkgbt/T23OKBaxSBBElSxrqTWvO3E7q5fxOlDG4m/wAf7fronJY+m6d3tuTrlZU9FBzs57LP/Q/Gq3Fj18DpnBjh8vPZL+2a9KPdsubbdefoWMVfF6bcQ0V6ffUJ7d1doBdXdFdIiOtxge+aAQOj1apViNv4wYNFWvHyMd18S5Ma97Pml+rZpz9XaKifiosrapzz3JI8NWrkr06dI3T+fLlH1w1cywgkSJIG3R6tH/+kjSIi/vefxKgxcWrd+nO9uPyoMtae1NhxLV326T+gqWLj3P9Q/7qX/nxEJ0+U6vE/dFby4GbO8aRuFj30ixytXHFMP5ne1qPvBWhoOiSEq0NCuNv4448ckCQNH9mixv0WPH5QLVuFKD4+TJs2nq5xTsamnmr53/gak/rRRUMK8KadO3dq4sSJNW7btGmT4uPjnT/v2bNHixYt0ieffKLw8HClpKTo/vvvV0jIpT+PvikCCZKk6xMtNY7flhyjF5cfVe6hohq322zlCg72lb9/zbez7fronIKCfXVHSozL+O3JMXr01we0/s1TBBJQgwvFFdqSma9mzYLUp2+U2/bt26x6790zevkvPbTmb8cvepyWNZyZAq5WkyZNUmJiostYs2b/+8t1Tk6OJk+erOuuu07z5s3TqVOn9NJLL+mLL77Q888/79G1EEi4pPzTpZKkqCaBbtvuunOXiooq5OcnJXax6CfT26jvD1wvBdjtlQoK9JWPj4/LuK+vj4KCfHX8ixJ99ZXd7b4J4LvunbfzVWSr0F3jWsrPz/X3x2Yr18LfH9TI0bHq0tVyyUACGpKbbrpJgwYNuuj2J598Uo0bN9arr76qsLAwSVLLli318MMPa8eOHerd23P31/EUGy6qosKhPy87Ij9/H5fLYxER/ho5qoV+Pr+Dnnymi2bObq+TJ0s0e8Z/tP7Nky7HiL8uTIWF5Trw6XmX8QOfnldhYdX9EKdOln77bwZoYDLWnZKPjzQ8tbnbtmee+lyVldLM2e29sDLg22Wz2VRe7n6/nM1m07/+9S+NGDHCGUeSNHz4cIWGhmrz5s0eXYfHzyCtXLlSL730krZt2+bpQ6Oe/fEPh5SdVagZs9upbbtQ5/i4Ca3c5g5LbaExqf/WkwtzNej2aIWGVv2nNW58S727/YzmPfCJ7n/wOsV3CNPnh4r0x4WH5O/vo/Jyh0pKuCcC+LrDecXat6dAN/VsrLiWrpfI9u0t0No1J/TYgs4u9wwCV5vCwkIVFha6jVssFlksNd/W8fOf/1zFxcXy9/dXz5499Ytf/EIJCQmSpAMHDqi8vFxdunRx2ScwMFCdO3dWTk6OR9fv8d+uwsJCnThxwtOHRT1b+myeVq86rpGjWmjKT9rUOr9x4wCNGhOrZUsPK2tfoXr3qbpnovuNjfX7hddr0YJDmj3jP5IkPz9pxMgWah9fpr9vO6PwMP6QB74uY13VmdgRd7renF1WVqnHHzmgm3pFupzVBa5G6enpSktLcxufOXOmZs2a5TIWEBCgO+64QzfffLMiIyN14MABvfTSSxo3bpxef/11tWvXTlarVZIUHR3tdszo6Gjt27fPo+uv0yfTv//97zof8IsvvrjsxeDqsGxpnl584YiGjWiuX/66Y533axEbLEk691WZy/htd8RowKBoHTpoU3FRhdq0DVVUk0BNvHu3/Px91LI1N5EC1crLK/XW+lNq1Nhftw50/SB4bdVxHc4r1twH4nXsaLFzvPrJtBPHS1Rkq+DGbFzUeXv9vdakSZOUmprqNl7T2aMePXqoR48ezp8HDhyoAQMG6M4771RaWpr++Mc/qqSkRFLVGSNTUFCQc7un1CmQJkyY4HaT7cU4HI46z8XVp/oL64YMa6ZfPZLwjf6/PHak6g/sJjXc0O3n56OETv/7jqQzZ0r16ac23XhjI74HCfia9/7xpb78skx3j49TYKDrbaInT5aoslKade9/atx34t17FBLiqw8+urk+lgpc0qUupdVFp06d1Lt3b3344YeSpODgqr+E2+3ulVdaWurc7il1CqTQ0FB16tRJU6ZMqXVuZmam3nrrrSteGOrfC386rBf+dEQ/HNpMv/ldJ/n6usdReXmlLlyodLv34dSpEr3+2gk1auyvpG6X/oWorHRo0ROHVFnh0JRptV++A75LMtZWXV4bnur+3UfDRrRQt+6N3MZf+9sJ7f73Of3m0QRFWLhkjWtHixYtnIFUfWmt+lLb11mtVsXExLiNX4k6/SZ16dJFp0+fvuSjd9UOHjx4xYtC/Xtt1XEtW3pYzVsE6aZekcp8y/VL56KaBKpXnyhdKK7Q0OSd6j+gqdq1D1WExV9HDhfrzbUndaG4Qo//4XqXb9wuLi7XxLv36NaBTRUbFyybrUJbNp1Wzic2zfhZO33/psj6fqvAVcuaX6od/zyrxK4R6tDR/YsjOyaEq2MNXyj5/j++lCT9oH8Tt6/MeGvDKZ08UXXp4auzZSorc+jPyw5Lqros/sOh7k/JAVeLY8eOKTKy6nOiY8eO8vf31/79+3X77bc759jtduXk5Gjo0KEefe06BVJSUpJefPFFFRQUqFEj97+9fJ3D4ZDD4fDI4lB/Pt5f9aTBqZOl+s1Dn7ptv/F7jdSrT5SCgv004Lam2p99Xu9uP6PiCxVq3DhAPXtFauKPW6tLV9ezRwEBvuqYEK7MTfk6Yy1VcLCfru8SoWefT6rxy++A77INGadUUVH1EIOnZKw9qd27ClzG/pR2WFLV7zWBhKvB2bNnFRXl+pmwa9cu7dy5UyNGjJAkRUREqHfv3srIyND06dOdj/pnZGSouLhYycnJHl2Tj6MONWO1WpWXl6cuXbooNDS0tumXzWaf/q0dGwCAq0144LJ6fb0fvFx/n7Pv/7ju723ixIkKCQlR9+7dFRkZqYMHD2r16tWKiIjQ66+/rtjYWEnSxx9/rLvuuksdOnTQ6NGjderUKb388svq2bOnli9f7tH11ymQ6guBBAD4LiGQqqxYsUIbNmzQ0aNHZbPZFBUVpX79+mnWrFnOOKq2a9cuLV682PlvsQ0ePFj33Xefx0/gEEgAAHgJgXT14p8aAQAAMBBIAAAABgIJAADAQCABAAAYCCQAAAADgQQAAGAgkAAAAAwEEgAAgIFAAgAAMBBIAAAABgIJAADAQCABAAAYCCQAAAADgQQAAGAgkAAAAAwEEgAAgIFAAgAAMBBIAAAABgIJAADA4O/tBQAAgPphs3t7BQ0HZ5AAAAAMBBIAAICBQAIAADAQSAAAAAYCCQAAwEAgAQAAGAgkAAAAA4EEAABgIJAAAAAMBBIAAICBQAIAADAQSAAAAAYCCQAAwEAgAQAAGAgkAAAAA4EEAABgIJAAAAAMBBIAAICBQAIAADAQSAAAAAYCCQAAwEAgAQAAGAgkAAAAA4EEAABgIJAAAAAMBBIAAIDB39sLAAAA9cNm9/YKGg7OIAEAABgIJAAAAAOBBAAAYCCQAAAADAQSAACAgUACAAAwEEgAAAAGvgcJAAB4VXZ2ttatW6edO3fqxIkTaty4sbp37645c+aoTZs2znkTJkzQRx995Lb/4MGD9dRTT3l0TQQSAADwqj//+c/as2ePkpOTlZCQIKvVqpUrV2rEiBF6/fXXFR8f75wbGxurOXPmuOwfFxfn8TURSAAAwKsmT56sxYsXKzAw0Dk2ePBgDR06VMuXL9eCBQuc4xaLRcOHD//W18Q9SAAAwKt69OjhEkeS1LZtW3Xo0EG5ublu88vLy1VUVPStrokzSAAAwOMKCwtVWFjoNm6xWGSxWGrd3+Fw6MyZM+rUqZPLeG5urrp166aysjJFR0dr/PjxmjZtmnx9PXvOh0ACAAAel56errS0NLfxmTNnatasWbXuv379ep0+fVpz5851jrVq1Uo9e/ZUQkKCbDabNm7cqKeeekonTpzQo48+6tH1+zgcDodHj3gFbPbp3l4CAAD1JjxwWb2+Xodn6+9zdvekRZd9Bik3N1djxoxRQkKC/vKXv1zy7NDs2bO1ZcsWbdq0Se3bt7/idVfjDBIAAPC4ul5KM1mtVk2fPl2NGjXSkiVLar10NmXKFGVmZmrnzp0EEgAAuPacP39eU6dO1fnz57Vq1SpFR0fXuk/z5s0lSQUFBR5dC4EEAAC8rrS0VD/96U91+PBhvfLKK3U+G3Ts2DFJUlRUlEfXw2P+AADAqyoqKjRnzhzt27dPS5YsUbdu3dzm2Gw22e12t/2WLVsmX19f9e7d26Nr4gwSAADwqgULFmj79u269dZbde7cOWVkZDi3hYWFadCgQfr44491//33a8iQIWrdurWKi4u1efNm7d+/X1OnTlWrVq08uiYCCQAAeNWnn34qSfr73/+uv//97y7b4uLiNGjQIMXGxqpHjx56++23debMGfn6+qpDhw5asGCBUlNTPb4mAgkAAHjVq6++WuucVq1a6ZlnnqmH1VThHiQAAAADgQQAAGAgkAAAAAwEEgAAgIFAAgAAMPAUGwAA3xE2e+1zUIUzSAAAAAYCCQAAwEAgAQAAGAgkAAAAA4EEAABgIJAAAAAMBBIAAICBQAIAADAQSAAAAAYCCQAAwEAgAQAAGAgkAAAAA4EEAABgIJAAAAAMBBIAAICBQAIAADAQSAAAAAYCCQAAwEAgAQAAGAgkAAAAA4EEAABgIJAAAAAMBBIAAICBQAIAADAQSAAAAAYCCQAAwEAgAQAAGPy9vQAAAFA/bHZvr6Dh4AwSAACAgUACAAAwEEgAAAAGAgkAAMBAIAEAABgIJAAAAAOBBAAAYCCQAAAADAQSAACAgUACAAAwEEgAAAAGAgkAAMBAIAEAABgIJAAAAAOBBAAAYCCQAAAADAQSAACAgUACAAAwEEgAAAAGAgkAAMBAIAEAAK+z2+1atGiR+vXrp6SkJI0ZM0Y7duzw2noIJAAA4HXz5s1Tenq6hg0bpoceeki+vr6aOnWq9u7d65X1EEgAAMCrsrOz9dZbb+mBBx7Qgw8+qLFjxyo9PV0tWrTQ4sWLvbImAgkAAHhVZmamAgICNHr0aOdYUFCQRo0apd27dys/P7/e1+Rf768IAACueYWFhSosLHQbt1gsslgsLmM5OTlq166dwsLCXMaTkpLkcDiUk5OjmJiYb3W9pqsqkMIDl3l7CQAAXLPOz6+/z9lnn31WaWlpbuMzZ87UrFmzXMasVquaNWvmNjc6OlqSOIMEAACuDZMmTVJqaqrbuHn2SJJKSkoUEBDgNh4UFCRJKi0t9fwCa0EgAQAAj6vpUtrFBAcHq6yszG28OoyqQ6k+cZM2AADwqujo6Bovo1mtVkmq9/uPJAIJAAB4WadOnZSXl6eioiKX8aysLOf2+kYgAQAAr0pOTlZZWZnWrFnjHLPb7Vq7dq169OhR4w3c3zbuQQIAAF51ww03KDk5WYsXL5bValXr1q21bt06nThxQk888YRX1uTjcDgcXnllAACA/yotLdXTTz+tDRs2qKCgQAkJCbrvvvvUp08fr6yHQAIAADBwDxIAAICBQAIAADAQSLhsdrtdixYtUr9+/ZSUlKQxY8Zox44d3l4WcM3Lz8/X4sWLNWHCBHXv3l0JCQnauXOnt5cFXFMIJFy2efPmKT09XcOGDdNDDz0kX19fTZ06VXv37vX20oBrWl5enpYvX67Tp08rISHB28sBrkncpI3Lkp2drdGjR2v+/PmaPHmypKonEIYMGaKYmBitXLnSuwsErmE2m01lZWWKjIzU1q1bNWPGDK1YsUI9e/b09tKAawZnkHBZMjMzFRAQoNGjRzvHgoKCNGrUKO3evdsr//Iy8F0RHh6uyMhIby8DuKYRSLgsOTk5ateuncLCwlzGk5KS5HA4lJOT46WVAQBw5QgkXBar1VrjPx4YHR0tSZxBAgA0aAQSLktJSYkCAgLcxoOCgiRV3Y8EAEBDRSDhsgQHB6usrMxtvDqMqkMJAICGiEDCZYmOjq7xMprVapWkGi+/AQDQUBBIuCydOnVSXl6eioqKXMazsrKc2wEAaKgIJFyW5ORklZWVac2aNc4xu92utWvXqkePHmrWrJkXVwcAwJXx9/YC0DDdcMMNSk5O1uLFi2W1WtW6dWutW7dOJ06c0BNPPOHt5QHXvKVLl0qScnNzJUkZGRnavXu3LBaLxo8f782lAdcEvkkbl620tFRPP/20NmzYoIKCAiUkJOi+++5Tnz59vL004Jp3sX9iJC4uTtu3b6/n1QDXHgIJAADAwD1IAAAABgIJAADAQCABAAAYCCQAAAADgQQAAGAgkAAAAAwEEgAAgIFAAgAAMBBIAAAABgIJAADA8P9htZ0O2fqUHQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmUjbDLdApmn"
      },
      "source": [
        "from sklearn import metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEdj9DEfc0HD",
        "outputId": "a159fc6b-48d7-4b5b-e335-5f6cd16bf9d0"
      },
      "source": [
        "print(metrics.classification_report(label_df,pred_df))\n",
        "\n",
        "metrics.confusion_matrix(label_df,pred_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.75      0.74      1000\n",
            "           1       0.74      0.74      0.74      1000\n",
            "\n",
            "    accuracy                           0.74      2000\n",
            "   macro avg       0.74      0.74      0.74      2000\n",
            "weighted avg       0.74      0.74      0.74      2000\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[746, 254],\n",
              "       [259, 741]])"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3JdR0Mw_EvD",
        "outputId": "38063977-ae5f-4b0e-9cee-af51744a91ab"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(\"Classification report\")\n",
        "print(classification_report(label_df,pred_df))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.75      0.74      1000\n",
            "           1       0.74      0.74      0.74      1000\n",
            "\n",
            "    accuracy                           0.74      2000\n",
            "   macro avg       0.74      0.74      0.74      2000\n",
            "weighted avg       0.74      0.74      0.74      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0z8e7qeW9jYP",
        "outputId": "f231ee59-7e89-4bcb-adf9-4641fb5a2efb"
      },
      "source": [
        "import pprint\n",
        "d = metrics.classification_report(label_df,pred_df, output_dict=True)\n",
        "pprint.pprint(d)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'0': {'f1-score': 0.744139650872818,\n",
            "       'precision': 0.7422885572139304,\n",
            "       'recall': 0.746,\n",
            "       'support': 1000},\n",
            " '1': {'f1-score': 0.7428571428571429,\n",
            "       'precision': 0.7447236180904523,\n",
            "       'recall': 0.741,\n",
            "       'support': 1000},\n",
            " 'accuracy': 0.7435,\n",
            " 'macro avg': {'f1-score': 0.7434983968649804,\n",
            "               'precision': 0.7435060876521913,\n",
            "               'recall': 0.7435,\n",
            "               'support': 2000},\n",
            " 'weighted avg': {'f1-score': 0.7434983968649803,\n",
            "                  'precision': 0.7435060876521914,\n",
            "                  'recall': 0.7435,\n",
            "                  'support': 2000}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "VuCTI965HfkZ",
        "outputId": "7b2ee65d-dca4-4100-cc8f-a164eff0443f"
      },
      "source": [
        "df = pd.DataFrame(d)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.742289</td>\n",
              "      <td>0.744724</td>\n",
              "      <td>0.7435</td>\n",
              "      <td>0.743506</td>\n",
              "      <td>0.743506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.746000</td>\n",
              "      <td>0.741000</td>\n",
              "      <td>0.7435</td>\n",
              "      <td>0.743500</td>\n",
              "      <td>0.743500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.744140</td>\n",
              "      <td>0.742857</td>\n",
              "      <td>0.7435</td>\n",
              "      <td>0.743498</td>\n",
              "      <td>0.743498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>0.7435</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     0            1  accuracy    macro avg  weighted avg\n",
              "precision     0.742289     0.744724    0.7435     0.743506      0.743506\n",
              "recall        0.746000     0.741000    0.7435     0.743500      0.743500\n",
              "f1-score      0.744140     0.742857    0.7435     0.743498      0.743498\n",
              "support    1000.000000  1000.000000    0.7435  2000.000000   2000.000000"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    }
  ]
}